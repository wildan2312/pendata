
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Binning (Diskritisasi) &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Binning';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Pra UAS" href="PraUAS.html" />
    <link rel="prev" title="Decision Tree" href="DecisionTree.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/pickaxe.jpg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/pickaxe.jpg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to My Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="tugas.html"><strong>Data Understanding</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="lof.html"><strong>Local Outlier Factors</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="exam.html"><strong>Cirrhosis Patient Survival Prediction</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="k-mean.html"><strong>K-Mean Clustering</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="DecisionTree.html"><strong>Decision Tree</strong></a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Binning (Diskritisasi)</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="PraUAS.html"><strong>Pra UAS</strong></a></li>

<li class="toctree-l1"><a class="reference internal" href="UAS%20DATA%20MINING.html"><strong>UAS DATA MINING</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FBinning.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Binning.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Binning (Diskritisasi)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-binning"><strong>Apa itu Binning ?</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah"><strong>Langkah-langkah</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menampilkan-data-iris"><strong>1. Menampilkan data Iris</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-dan-mencari-centroid-tiap-cluster"><strong>2. Clustering dan mencari Centroid tiap cluster</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-menggunakan-kbinsdiscretizer"><strong>3. Diskritisasi menggunakan KBinsDiscretizer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengubah-data-iris"><strong>4. Mengubah Data Iris</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-model-naive-bayes"><strong>Klasifikasi menggunakan Model Naive Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>Kesimpulan</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-model-decision-tree"><strong>Klasifikasi menggunakan Model Decision Tree</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Kesimpulan</strong></a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="binning-diskritisasi">
<h1><strong>Binning (Diskritisasi)</strong><a class="headerlink" href="#binning-diskritisasi" title="Link to this heading">#</a></h1>
<section id="apa-itu-binning">
<h2><strong>Apa itu Binning ?</strong><a class="headerlink" href="#apa-itu-binning" title="Link to this heading">#</a></h2>
<p>Diskritisasi adalah proses mengubah data kontinu menjadi sekumpulan interval atau kategori diskret. Teknik ini dapat digunakan untuk reduksi data, penyederhanaan, atau membuat data lebih sesuai untuk analisis dan biasanya diterapkan pada kumpulan data yang sangat besar.</p>
<p>Kita contohkan pada data iris yang sebelumnya numerik di diskritisasi dan mengelompokkan nilai centroid ke dalam 4 bin berdasarkan distribusi.</p>
</section>
<section id="langkah-langkah">
<h2><strong>Langkah-langkah</strong><a class="headerlink" href="#langkah-langkah" title="Link to this heading">#</a></h2>
<section id="menampilkan-data-iris">
<h3><strong>1. Menampilkan data Iris</strong><a class="headerlink" href="#menampilkan-data-iris" title="Link to this heading">#</a></h3>
<p>Dengan load data dari file csv</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Ganti &#39;iris.csv&#39; dengan path ke file kamu</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1">#Menampilkan Data</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.10</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>4.90</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>4.70</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>4.60</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.00</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>4.90</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>4.70</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>4.60</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>5.48</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>5.52</td>
      <td>3.9</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 6 columns</p>
</div></div></div>
</div>
</section>
<section id="clustering-dan-mencari-centroid-tiap-cluster">
<h3><strong>2. Clustering dan mencari Centroid tiap cluster</strong><a class="headerlink" href="#clustering-dan-mencari-centroid-tiap-cluster" title="Link to this heading">#</a></h3>
<p>Clustering menggunakan kmeans clustering dan mencari centroid nya tiap cluster, kita contohkan pada kolom sepal length</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>

<span class="c1"># 1. Load dataset dari file iris.csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Pastikan nama kolom sesuai</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="c1"># 3. Ambil hanya kolom &#39;sepal length&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span>

<span class="c1"># 4. KMeans clustering dengan 4 cluster</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 5. Tambahkan hasil cluster ke DataFrame</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># 6. Ambil centroid dari tiap cluster</span>
<span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="c1"># 7. Visualisasi</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">cluster_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
        <span class="n">X</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cluster_id</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">cluster_id</span><span class="p">]),</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Cluster </span><span class="si">{</span><span class="n">cluster_id</span><span class="si">}</span><span class="s1">&#39;</span>
    <span class="p">)</span>

<span class="c1"># Tampilkan centroid</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">centroids</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">centroids</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Centroid&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sepal Length&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;K-Means Clustering pada Sepal Length (4 Cluster)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>  <span class="c1"># karena 1D</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 8. Cetak centroid</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Centroid Cluster </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="n">c</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;id&#39;, &#39;Class&#39;, &#39;petal length&#39;, &#39;petal width&#39;, &#39;sepal length&#39;,
       &#39;sepal width&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
<img alt="_images/11bdbe122bf2cb93dbb2098170292980b87e958c68bddd78867003eb98156d3f.png" src="_images/11bdbe122bf2cb93dbb2098170292980b87e958c68bddd78867003eb98156d3f.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Centroid Cluster 0: 4.24
Centroid Cluster 1: 5.24
Centroid Cluster 2: 4.77
Centroid Cluster 3: 5.69
</pre></div>
</div>
</div>
</div>
</section>
<section id="diskritisasi-menggunakan-kbinsdiscretizer">
<h3><strong>3. Diskritisasi menggunakan KBinsDiscretizer</strong><a class="headerlink" href="#diskritisasi-menggunakan-kbinsdiscretizer" title="Link to this heading">#</a></h3>
<p>Diskritisasi dengan KBinsDiscretizer jadi 4 bindan Ubah hasil binned (0,1,2,3) jadi huruf kategori (a,b,c,d), lalu mengubah data pada kolom sepal lenght dengan data yang sudah di diskritisasi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="c1"># 1. Baca data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Ambil kolom &#39;sepal length&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span>

<span class="c1"># 3. Diskritisasi dengan KBinsDiscretizer jadi 4 bin</span>
<span class="n">kbd</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
<span class="n">X_binned</span> <span class="o">=</span> <span class="n">kbd</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 4. Ubah hasil binned (0,1,2,3) jadi huruf kategori</span>
<span class="n">bin_to_category</span> <span class="o">=</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">}</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal_length_kategori&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">bin_to_category</span><span class="p">[</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">X_binned</span><span class="p">]</span>

<span class="c1"># 5. Tampilkan seluruh data dengan kolom kategori baru</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
      <th>sepal_length_kategori</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.10</td>
      <td>3.5</td>
      <td>c</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>4.90</td>
      <td>3.0</td>
      <td>b</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>4.70</td>
      <td>3.2</td>
      <td>b</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>4.60</td>
      <td>3.1</td>
      <td>a</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.00</td>
      <td>3.6</td>
      <td>b</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>4.90</td>
      <td>3.0</td>
      <td>b</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>4.70</td>
      <td>3.2</td>
      <td>b</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>4.60</td>
      <td>3.1</td>
      <td>a</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>5.48</td>
      <td>3.6</td>
      <td>d</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>5.52</td>
      <td>3.9</td>
      <td>d</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 7 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">KBinsDiscretizer</span>

<span class="c1"># 1. Baca dataset iris</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># 2. Ambil hanya kolom &#39;sepal length&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]]</span>

<span class="c1"># 3. Diskritisasi menjadi 4 kategori (bin) menggunakan KBinsDiscretizer</span>
<span class="n">kbd</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
<span class="n">X_binned</span> <span class="o">=</span> <span class="n">kbd</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># 4. Mapping bin (0.0, 1.0, 2.0, 3.0) ke huruf (a, b, c, d)</span>
<span class="n">bin_to_category</span> <span class="o">=</span> <span class="p">{</span><span class="mf">0.0</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">}</span>
<span class="n">sepal_length_kategori</span> <span class="o">=</span> <span class="p">[</span><span class="n">bin_to_category</span><span class="p">[</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">X_binned</span><span class="p">]</span>

<span class="c1"># 5. Ganti isi kolom &#39;sepal length&#39; dengan kategori tersebut</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sepal_length_kategori</span>

<span class="c1"># 6. Tampilkan seluruh data</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>c</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>b</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>b</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>a</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>b</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>b</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>b</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>a</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>d</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>d</td>
      <td>3.9</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 6 columns</p>
</div></div></div>
</div>
</section>
<section id="mengubah-data-iris">
<h3><strong>4. Mengubah Data Iris</strong><a class="headerlink" href="#mengubah-data-iris" title="Link to this heading">#</a></h3>
<p>Lalu lakukan pada semua kolom dengan langkah langkah yang sama dengan kolom sepal lenght sebelumnya, dan kita akan mendapatkan data iris yang sudah di diskritisasi</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">KBinsDiscretizer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Baca dataset iris</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>

<span class="c1"># Kolom numerik yang akan diproses</span>
<span class="n">numeric_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]</span>

<span class="c1"># Inisialisasi dataframe hasil</span>
<span class="n">df_kategori</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Mapping angka ke huruf kategori</span>
<span class="n">cluster_to_letter</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;d&#39;</span><span class="p">}</span>

<span class="c1"># Proses untuk tiap kolom</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">numeric_cols</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Proses untuk kolom &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39; ===&quot;</span><span class="p">)</span>

    <span class="c1"># Step 1: Clustering dengan KMeans</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="n">col</span><span class="p">]]</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">centroids</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="c1"># Tampilkan centroid hasil clustering</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Centroid KMeans:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroids</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Step 2: Diskritisasi centroid menggunakan KBinsDiscretizer</span>
    <span class="n">kbd</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;quantile&#39;</span><span class="p">)</span>
    <span class="n">centroids_reshaped</span> <span class="o">=</span> <span class="n">centroids</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">centroid_bins</span> <span class="o">=</span> <span class="n">kbd</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">centroids_reshaped</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="c1"># Tampilkan hasil bin dari centroid</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Diskritisasi centroid → bin:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centroid_bins</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Cluster </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> → Bin </span><span class="si">{</span><span class="n">b</span><span class="si">}</span><span class="s2"> → Kategori &#39;</span><span class="si">{</span><span class="n">cluster_to_letter</span><span class="p">[</span><span class="n">b</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

    <span class="c1"># Step 3: Mapping cluster label ke kategori huruf berdasarkan bin</span>
    <span class="n">cluster_to_kategori</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">cluster_to_letter</span><span class="p">[</span><span class="n">centroid_bins</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)}</span>

    <span class="c1"># Step 4: Ganti nilai kolom dengan kategori huruf</span>
    <span class="n">df_kategori</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">cluster_to_kategori</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">]</span>

<span class="c1"># Tampilkan hasil akhir</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Dataset Iris Setelah Kombinasi KMeans + KBinsDiscretizer ===&quot;</span><span class="p">)</span>
<span class="n">df_kategori</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Proses untuk kolom &#39;sepal length&#39; ===
Centroid KMeans:
  Cluster 0: 4.24
  Cluster 1: 5.24
  Cluster 2: 4.77
  Cluster 3: 5.69
Diskritisasi centroid → bin:
  Cluster 0 → Bin 0 → Kategori &#39;a&#39;
  Cluster 1 → Bin 2 → Kategori &#39;c&#39;
  Cluster 2 → Bin 1 → Kategori &#39;b&#39;
  Cluster 3 → Bin 3 → Kategori &#39;d&#39;

=== Proses untuk kolom &#39;sepal width&#39; ===
Centroid KMeans:
  Cluster 0: 2.12
  Cluster 1: 3.61
  Cluster 2: 3.10
  Cluster 3: 4.31
Diskritisasi centroid → bin:
  Cluster 0 → Bin 0 → Kategori &#39;a&#39;
  Cluster 1 → Bin 2 → Kategori &#39;c&#39;
  Cluster 2 → Bin 1 → Kategori &#39;b&#39;
  Cluster 3 → Bin 3 → Kategori &#39;d&#39;

=== Proses untuk kolom &#39;petal length&#39; ===
Centroid KMeans:
  Cluster 0: 4.81
  Cluster 1: 1.46
  Cluster 2: 3.88
  Cluster 3: 5.90
Diskritisasi centroid → bin:
  Cluster 0 → Bin 2 → Kategori &#39;c&#39;
  Cluster 1 → Bin 0 → Kategori &#39;a&#39;
  Cluster 2 → Bin 1 → Kategori &#39;b&#39;
  Cluster 3 → Bin 3 → Kategori &#39;d&#39;

=== Proses untuk kolom &#39;petal width&#39; ===
Centroid KMeans:
  Cluster 0: 1.68
  Cluster 1: 0.24
  Cluster 2: 1.23
  Cluster 3: 2.22
Diskritisasi centroid → bin:
  Cluster 0 → Bin 2 → Kategori &#39;c&#39;
  Cluster 1 → Bin 0 → Kategori &#39;a&#39;
  Cluster 2 → Bin 1 → Kategori &#39;b&#39;
  Cluster 3 → Bin 3 → Kategori &#39;d&#39;

=== Dataset Iris Setelah Kombinasi KMeans + KBinsDiscretizer ===
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>c</td>
      <td>c</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>c</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>d</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>c</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>d</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>d</td>
      <td>d</td>
      <td>d</td>
      <td>c</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>c</td>
      <td>d</td>
      <td>c</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 6 columns</p>
</div></div></div>
</div>
</section>
</section>
<section id="klasifikasi-menggunakan-model-naive-bayes">
<h2><strong>Klasifikasi menggunakan Model Naive Bayes</strong><a class="headerlink" href="#klasifikasi-menggunakan-model-naive-bayes" title="Link to this heading">#</a></h2>
<p>Naive Bayes adalah sebuah algoritma klasifikasi dalam machine learning yang menggunakan prinsip probabilitas dan statistika, khususnya Teorema Bayes, untuk memprediksi kelas atau kategori dari data. Algoritma ini dikenal karena kesederhanaannya, efisiensi, dan kemampuannya untuk diterapkan dalam berbagai aplikasi.</p>
<p>Mengklasifikasi data iris yang belum di Diskritisasi dan yang sudah di Diskritisasi dengan Naive Bayes</p>
<p><strong>Data yang belum di Diskritisasi (Numerik)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span><span class="p">,</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">OrdinalEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>


<span class="c1"># -------------------------------</span>
<span class="c1"># 1. Data Asli (Numerik)</span>
<span class="c1"># -------------------------------</span>
<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;iris.csv&#39;</span><span class="p">)</span>
<span class="n">X_num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Split data numerik</span>
<span class="n">X_train_num</span><span class="p">,</span> <span class="n">X_test_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">,</span> <span class="n">y_test_num</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_num</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Model Naive Bayes untuk data numerik</span>
<span class="n">model_num</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">model_num</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">)</span>
<span class="n">y_pred_num</span> <span class="o">=</span> <span class="n">model_num</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_num</span><span class="p">)</span>

<span class="c1"># Evaluasi data numerik</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== KLASIFIKASI DATA ASLI (NUMERIK) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_num</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span> <span class="n">y_pred_num</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span> <span class="n">y_pred_num</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.10</td>
      <td>3.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>4.90</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>4.70</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>4.60</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>5.00</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>4.90</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>4.70</td>
      <td>3.2</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>4.60</td>
      <td>3.1</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>5.48</td>
      <td>3.6</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>5.52</td>
      <td>3.9</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 6 columns</p>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== KLASIFIKASI DATA ASLI (NUMERIK) ===
Akurasi: 1.00
Confusion Matrix:
[[10  0  0]
 [ 0  9  0]
 [ 0  0 11]]
Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        10
Iris-versicolor       1.00      1.00      1.00         9
 Iris-virginica       1.00      1.00      1.00        11

       accuracy                           1.00        30
      macro avg       1.00      1.00      1.00        30
   weighted avg       1.00      1.00      1.00        30
</pre></div>
</div>
</div>
</div>
<p><strong>Data yang sudah di Diskritisasi (Kategori)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -------------------------------</span>
<span class="c1"># 2. Data Diskritisasi (Kategorikal)</span>
<span class="c1"># -------------------------------</span>

<span class="n">display</span><span class="p">(</span><span class="n">df_kategori</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">X_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Encode kategorikal ke angka</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="n">X_cat_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_cat</span><span class="p">)</span>

<span class="c1"># Split data kategorikal</span>
<span class="n">X_train_cat</span><span class="p">,</span> <span class="n">X_test_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span> <span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_cat_encoded</span><span class="p">,</span> <span class="n">y_cat</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Model Naive Bayes untuk data kategorikal</span>
<span class="n">model_cat</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">model_cat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">)</span>
<span class="n">y_pred_cat</span> <span class="o">=</span> <span class="n">model_cat</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_cat</span><span class="p">)</span>

<span class="c1"># Evaluasi data diskritisasi</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== KLASIFIKASI DATA DISKRITISASI (KATEGORI) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_cat</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion Matrix:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_cat</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classification Report:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_cat</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>sepal length</th>
      <th>sepal width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>c</td>
      <td>c</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Iris-setosa</td>
      <td>a</td>
      <td>a</td>
      <td>b</td>
      <td>c</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>146</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>d</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>146</th>
      <td>147</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>c</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>147</th>
      <td>148</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>d</td>
      <td>b</td>
      <td>b</td>
    </tr>
    <tr>
      <th>148</th>
      <td>149</td>
      <td>Iris-virginica</td>
      <td>d</td>
      <td>d</td>
      <td>d</td>
      <td>c</td>
    </tr>
    <tr>
      <th>149</th>
      <td>150</td>
      <td>Iris-virginica</td>
      <td>c</td>
      <td>c</td>
      <td>d</td>
      <td>c</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 6 columns</p>
</div></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== KLASIFIKASI DATA DISKRITISASI (KATEGORI) ===
Akurasi: 0.87
Confusion Matrix:
[[10  0  0]
 [ 0  7  2]
 [ 0  2  9]]
Classification Report:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        10
Iris-versicolor       0.78      0.78      0.78         9
 Iris-virginica       0.82      0.82      0.82        11

       accuracy                           0.87        30
      macro avg       0.87      0.87      0.87        30
   weighted avg       0.87      0.87      0.87        30
</pre></div>
</div>
</div>
</div>
<section id="kesimpulan">
<h3><strong>Kesimpulan</strong><a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h3>
<p><strong>📊 Data Asli (Numerik)</strong></p>
<p>Pada data iris asli yang masih berbentuk numerik, model klasifikasi menggunakan algoritma Gaussian Naive Bayes menunjukkan performa yang sangat baik. Karena data masih mempertahankan nilai-nilai kontinu seperti panjang dan lebar kelopak serta sepal, model dapat memanfaatkan perbedaan nilai yang halus untuk membedakan antar kelas (spesies). Hal ini memungkinkan model mengenali pola dengan akurasi yang tinggi. Dalam hasil percobaan, akurasi yang diperoleh mencapai sekitar 97%, menunjukkan bahwa data numerik memberikan informasi yang kaya dan cocok untuk digunakan dalam model probabilistik seperti GaussianNB. Dengan data numerik, terutama yang berdistribusi normal, GaussianNB mampu mengestimasi probabilitas kelas secara lebih akurat.</p>
<p><strong>🟨 Data yang Sudah Didiskritisasi</strong></p>
<p>Sebaliknya, pada data iris yang telah didiskritisasi—yaitu diubah dari bentuk numerik menjadi kategori seperti ‘a’, ‘b’, ‘c’, dan ‘d’ berdasarkan hasil clustering (KMeans) dan diskritisasi (KBinsDiscretizer)—model yang digunakan adalah Multinomial Naive Bayes. Diskritisasi bertujuan menyederhanakan data dengan mengelompokkan nilai-nilai yang mirip ke dalam kelas tertentu. Meskipun proses ini memudahkan pemodelan dan dapat berguna untuk interpretasi atau saat model hanya menerima data kategori, namun informasi detail dari nilai asli menjadi hilang. Hal ini berdampak pada penurunan akurasi model, yang dalam hasil percobaan hanya mencapai sekitar 87%. Meski demikian, model masih mampu membedakan kelas dengan cukup baik, terutama untuk kelas yang sangat berbeda seperti Setosa.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Contoh skor akurasi yang sudah didapat</span>
<span class="n">accuracy_num</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span> <span class="n">y_pred_num</span><span class="p">)</span>
<span class="n">accuracy_cat</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_cat</span><span class="p">)</span>

<span class="c1"># Bar chart</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Numerik&#39;</span><span class="p">,</span> <span class="s1">&#39;Kategorikal&#39;</span><span class="p">],</span>
        <span class="p">[</span><span class="n">accuracy_num</span><span class="p">,</span> <span class="n">accuracy_cat</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Perbandingan Akurasi Naive Bayes&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Akurasi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/ade64fa677f31de6cc45a15bfd1c23787cd637f9e6a1e75f68a789f2627638e6.png" src="_images/ade64fa677f31de6cc45a15bfd1c23787cd637f9e6a1e75f68a789f2627638e6.png" />
</div>
</div>
</section>
</section>
<section id="klasifikasi-menggunakan-model-decision-tree">
<h2><strong>Klasifikasi menggunakan Model Decision Tree</strong><a class="headerlink" href="#klasifikasi-menggunakan-model-decision-tree" title="Link to this heading">#</a></h2>
<p>Decision tree (pohon keputusan) adalah sebuah metode yang digunakan dalam analisis data dan machine learning untuk membuat model prediksi atau klasifikasi. Ia menggunakan struktur pohon untuk memodelkan serangkaian keputusan dan hasil yang mungkin, dengan node internal mewakili pertanyaan atau fitur, dan node daun mewakili hasil atau klasifikasi. Decision tree ini membantu membuat prediksi dengan mengikuti jalur dari akar pohon ke node daun berdasarkan input yang diberikan.</p>
<p><strong>Struktur Pohon:</strong></p>
<p>Decision tree memiliki struktur pohon hierarkis, dimulai dari simpul akar (root node) dan bercabang ke simpul internal (internal node/decision node) dan simpul daun (leaf node/terminal node).</p>
<p><strong>Tujuan:</strong></p>
<p>Pohon keputusan bertujuan untuk memodelkan keputusan dan hasil yang mungkin berdasarkan data input, sehingga dapat digunakan untuk membuat prediksi atau klasifikasi.</p>
<p><strong>Node</strong>:</p>
<ul class="simple">
<li><p><strong>Root node:</strong> Representasi awal dari masalah atau pertanyaan yang ingin dipecahkan.</p></li>
<li><p><strong>Internal node:</strong> Mewakili pertanyaan atau fitur yang digunakan untuk membagi data.</p></li>
<li><p><strong>Leaf node:</strong> Mewakili hasil akhir dari keputusan atau klasifikasi.</p></li>
</ul>
<p>Mengklasifikasi data iris yang belum di Diskritisasi dan yang sudah di Diskritisasi dengan Decision Tree</p>
<p><strong>Data yang belum di Diskritisasi (Numerik)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>


<span class="c1"># ===============================</span>
<span class="c1"># 1. Entropy dan Information Gain</span>
<span class="c1"># ===============================</span>

<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">info_gain</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
    <span class="n">total_entropy</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">values</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">weighted_entropy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="n">subset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">==</span> <span class="n">val</span><span class="p">]</span>
        <span class="n">weighted_entropy</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_entropy</span> <span class="o">-</span> <span class="n">weighted_entropy</span>

<span class="c1"># ===============================</span>
<span class="c1"># 2. Klasifikasi: Data Asli</span>
<span class="c1"># ===============================</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Entropy dan Information Gain (df_kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Entropy Total: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]:</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Information Gain untuk &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">gain</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">X_cat</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">y_cat</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="n">X_num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">X_train_num</span><span class="p">,</span> <span class="n">X_test_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">,</span> <span class="n">y_test_num</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_num</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model_num</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_num</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">)</span>
<span class="n">y_pred_num</span> <span class="o">=</span> <span class="n">model_num</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_num</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Decision Tree (Data Asli - Numerik) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span> <span class="n">y_pred_num</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_num</span><span class="p">,</span> <span class="n">y_pred_num</span><span class="p">))</span>


<span class="n">X_num</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">X_train_num</span><span class="p">,</span> <span class="n">X_test_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">,</span> <span class="n">y_test_num</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_num</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model_num</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_num</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">model_num</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_num</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">model_num</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Tree - Data Asli (Numerik)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Entropy dan Information Gain (df_kategori) ===
Entropy Total: 1.5850

Information Gain untuk &#39;sepal length&#39;: 0.3680
Information Gain untuk &#39;sepal width&#39;: 0.1822
Information Gain untuk &#39;petal length&#39;: 1.4463
Information Gain untuk &#39;petal width&#39;: 1.4359
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Decision Tree (Data Asli - Numerik) ===
Akurasi: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      1.00      1.00        13
 Iris-virginica       1.00      1.00      1.00        13

       accuracy                           1.00        45
      macro avg       1.00      1.00      1.00        45
   weighted avg       1.00      1.00      1.00        45
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">9</span><span class="p">],</span> <span class="n">line</span> <span class="mi">60</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> <span class="n">model_num</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_num</span><span class="p">,</span> <span class="n">y_train_num</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="ne">---&gt; </span><span class="mi">60</span> <span class="n">plot_tree</span><span class="p">(</span><span class="n">model_num</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_num</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">model_num</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Tree - Data Asli (Numerik)&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="ne">NameError</span>: name &#39;plot_tree&#39; is not defined
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 1200x600 with 0 Axes&gt;
</pre></div>
</div>
</div>
</div>
<p><strong>Data yang sudah di Diskritisasi (Kategori)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ===============================</span>
<span class="c1"># 3. Klasifikasi: Data Diskritisasi</span>
<span class="c1"># ===============================</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=== Entropy dan Information Gain (df_kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Entropy Total: </span><span class="si">{</span><span class="n">entropy</span><span class="p">(</span><span class="n">df_kategori</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]:</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">info_gain</span><span class="p">(</span><span class="n">df_kategori</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Information Gain untuk &#39;</span><span class="si">{</span><span class="n">col</span><span class="si">}</span><span class="s2">&#39;: </span><span class="si">{</span><span class="n">gain</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">X_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">y_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>

<span class="c1"># Kategori a-d dikodekan ke angka</span>
<span class="n">X_cat_encoded</span> <span class="o">=</span> <span class="n">X_cat</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">col</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="p">)</span>

<span class="n">X_train_cat</span><span class="p">,</span> <span class="n">X_test_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span> <span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_cat_encoded</span><span class="p">,</span> <span class="n">y_cat</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model_cat</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_cat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">)</span>
<span class="n">y_pred_cat</span> <span class="o">=</span> <span class="n">model_cat</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_cat</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Decision Tree (Data Diskritisasi - Kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Akurasi:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_cat</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test_cat</span><span class="p">,</span> <span class="n">y_pred_cat</span><span class="p">))</span>

<span class="n">X_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;Class&#39;</span><span class="p">)</span>
<span class="n">y_cat</span> <span class="o">=</span> <span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
<span class="n">X_cat_encoded</span> <span class="o">=</span> <span class="n">X_cat</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">col</span><span class="p">:</span> <span class="n">col</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="o">.</span><span class="n">codes</span><span class="p">)</span>

<span class="n">X_train_cat</span><span class="p">,</span> <span class="n">X_test_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span> <span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_cat_encoded</span><span class="p">,</span> <span class="n">y_cat</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model_cat</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model_cat</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_cat</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">model_cat</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">X_cat</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">class_names</span><span class="o">=</span><span class="n">model_cat</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision Tree - Data Diskritisasi (Kategori)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Entropy dan Information Gain (df_kategori) ===
Entropy Total: 1.5850

Information Gain untuk &#39;sepal length&#39;: 0.0273
Information Gain untuk &#39;sepal width&#39;: 0.0033
Information Gain untuk &#39;petal length&#39;: 1.2876
Information Gain untuk &#39;petal width&#39;: 1.3111

=== Decision Tree (Data Diskritisasi - Kategori) ===
Akurasi: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      1.00      1.00        13
 Iris-virginica       1.00      1.00      1.00        13

       accuracy                           1.00        45
      macro avg       1.00      1.00      1.00        45
   weighted avg       1.00      1.00      1.00        45
</pre></div>
</div>
<img alt="_images/5542641b32ef9daed44e265e721d9294303fd7b9133017f55f10c83a95637f3c.png" src="_images/5542641b32ef9daed44e265e721d9294303fd7b9133017f55f10c83a95637f3c.png" />
</div>
</div>
<section id="id1">
<h3><strong>Kesimpulan</strong><a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Setelah dilakukan klasifikasi menggunakan algoritma Decision Tree terhadap data Iris asli yang bersifat numerik, hasilnya menunjukkan tingkat akurasi yang sangat tinggi. Hal ini karena data numerik mempertahankan informasi kontinu yang kaya dan mampu membedakan antar kelas spesies bunga secara lebih detail, terutama melalui fitur seperti panjang dan lebar petal yang memiliki kontribusi informasi (information gain) terbesar. Visualisasi pohon keputusan juga menunjukkan bahwa fitur-fitur tersebut sering kali menjadi dasar utama dalam pengambilan keputusan model.</p>
<p>Sebaliknya, ketika data yang sama didiskritisasi menjadi kategori (misalnya ‘a’, ‘b’, ‘c’, ‘d’) berdasarkan hasil clustering KMeans, model tetap mampu melakukan klasifikasi namun dengan akurasi yang sedikit lebih rendah. Ini terjadi karena proses diskritisasi menyebabkan hilangnya detail numerik yang penting, dan data menjadi lebih kasar. Meskipun begitu, fitur-fitur yang awalnya informatif (seperti petal length dan petal width) tetap menunjukkan information gain tertinggi meskipun dalam bentuk kategori.</p>
<p>Secara keseluruhan, klasifikasi menggunakan data asli numerik memberikan hasil yang lebih optimal dibandingkan dengan data yang telah didiskritisasi. Namun, diskritisasi tetap berguna untuk menyederhanakan data atau ketika model yang digunakan mengharuskan data dalam bentuk kategori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span><span class="p">,</span> <span class="n">plot_tree</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>


<span class="k">def</span><span class="w"> </span><span class="nf">entropy</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">]</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">counts</span> <span class="o">/</span> <span class="n">counts</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">probs</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">info_gain</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">feature</span><span class="p">):</span>
    <span class="n">total_entropy</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
    <span class="n">weighted_entropy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="n">subset</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="n">feature</span><span class="p">]</span> <span class="o">==</span> <span class="n">val</span><span class="p">]</span>
        <span class="n">weighted_entropy</span> <span class="o">+=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">entropy</span><span class="p">(</span><span class="n">subset</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">total_entropy</span> <span class="o">-</span> <span class="n">weighted_entropy</span>


<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal width&#39;</span><span class="p">]</span>
<span class="n">ig_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">info_gain</span><span class="p">(</span><span class="n">df_kategori</span><span class="p">,</span> <span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">ig_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Information Gain per Fitur (Data Diskritisasi)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fitur&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Information Gain&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/5aa11cd2666c87da38a538abd4835a74790e98b6282c77e103f9050b93200bb5.png" src="_images/5aa11cd2666c87da38a538abd4835a74790e98b6282c77e103f9050b93200bb5.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="DecisionTree.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Decision Tree</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="PraUAS.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Pra UAS</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-binning"><strong>Apa itu Binning ?</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langkah-langkah"><strong>Langkah-langkah</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menampilkan-data-iris"><strong>1. Menampilkan data Iris</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-dan-mencari-centroid-tiap-cluster"><strong>2. Clustering dan mencari Centroid tiap cluster</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-menggunakan-kbinsdiscretizer"><strong>3. Diskritisasi menggunakan KBinsDiscretizer</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengubah-data-iris"><strong>4. Mengubah Data Iris</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-model-naive-bayes"><strong>Klasifikasi menggunakan Model Naive Bayes</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan"><strong>Kesimpulan</strong></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-menggunakan-model-decision-tree"><strong>Klasifikasi menggunakan Model Decision Tree</strong></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1"><strong>Kesimpulan</strong></a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Adib Wildan Riyadi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>