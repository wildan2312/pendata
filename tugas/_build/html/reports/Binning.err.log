Traceback (most recent call last):
  File "/home/codespace/.local/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 154, in wrapped
    asyncio.get_running_loop()
RuntimeError: no running event loop

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 1319, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/jupyter_core/utils/__init__.py", line 158, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python/3.12.1/lib/python3.12/asyncio/base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/home/codespace/.local/lib/python3.12/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score


# ===============================
# 1. Entropy dan Information Gain
# ===============================

def entropy(data):
    labels = data['Class']
    _, counts = np.unique(labels, return_counts=True)
    probs = counts / counts.sum()
    return -np.sum(probs * np.log2(probs))

def info_gain(data, feature):
    total_entropy = entropy(data)
    values, counts = np.unique(data[feature], return_counts=True)
    weighted_entropy = 0
    for val in values:
        subset = data[data[feature] == val]
        weighted_entropy += (len(subset) / len(data)) * entropy(subset)
    return total_entropy - weighted_entropy

# ===============================
# 2. Klasifikasi: Data Asli
# ===============================
print("=== Entropy dan Information Gain (df_kategori) ===")
print(f"Entropy Total: {entropy(df):.4f}\n")
for col in ['sepal length', 'sepal width', 'petal length', 'petal width']:
    gain = info_gain(df, col)
    print(f"Information Gain untuk '{col}': {gain:.4f}")
X_cat = df.drop(columns='Class')
y_cat = df['Class']

X_num = df.drop(columns='Class')
y = df['Class']
X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y, test_size=0.3, random_state=42)

model_num = DecisionTreeClassifier(random_state=42)
model_num.fit(X_train_num, y_train_num)
y_pred_num = model_num.predict(X_test_num)

print("\n=== Decision Tree (Data Asli - Numerik) ===")
print("Akurasi:", accuracy_score(y_test_num, y_pred_num))
print(classification_report(y_test_num, y_pred_num))


X_num = df.drop(columns='Class')
y = df['Class']
X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y, test_size=0.3, random_state=42)

model_num = DecisionTreeClassifier(random_state=42)
model_num.fit(X_train_num, y_train_num)

plt.figure(figsize=(12, 6))
plot_tree(model_num, feature_names=X_num.columns, class_names=model_num.classes_, filled=True)
plt.title("Decision Tree - Data Asli (Numerik)")
plt.show()



------------------

----- stdout -----
=== Entropy dan Information Gain (df_kategori) ===
Entropy Total: 1.5850

Information Gain untuk 'sepal length': 0.3680
Information Gain untuk 'sepal width': 0.1822
Information Gain untuk 'petal length': 1.4463
Information Gain untuk 'petal width': 1.4359
----- stdout -----

=== Decision Tree (Data Asli - Numerik) ===
Akurasi: 1.0
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        19
Iris-versicolor       1.00      1.00      1.00        13
 Iris-virginica       1.00      1.00      1.00        13

       accuracy                           1.00        45
      macro avg       1.00      1.00      1.00        45
   weighted avg       1.00      1.00      1.00        45
------------------

[31m---------------------------------------------------------------------------[39m
[31mNameError[39m                                 Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[9][39m[32m, line 60[39m
[32m     57[39m model_num.fit(X_train_num, y_train_num)
[32m     59[39m plt.figure(figsize=([32m12[39m, [32m6[39m))
[32m---> [39m[32m60[39m [43mplot_tree[49m(model_num, feature_names=X_num.columns, class_names=model_num.classes_, filled=[38;5;28;01mTrue[39;00m)
[32m     61[39m plt.title([33m"[39m[33mDecision Tree - Data Asli (Numerik)[39m[33m"[39m)
[32m     62[39m plt.show()

[31mNameError[39m: name 'plot_tree' is not defined

